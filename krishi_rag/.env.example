# Environment variables template for Krishi Sahayak RAG backend

# Ollama Configuration
# No API key required - Ollama runs locally
# Ensure Ollama is installed and running: http://localhost:11434
# Pull model: ollama pull llama3:8b

# Model Configuration
MODEL_NAME=llama3:8b
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Vector Store Configuration
VECTOR_STORE_PATH=./vector_store/aif_index
PDF_DATA_PATH=./data/pdfs

# Retrieval Configuration
TOP_K=5
CHUNK_SIZE=800
CHUNK_OVERLAP=150

# LLM Configuration
TEMPERATURE=0
