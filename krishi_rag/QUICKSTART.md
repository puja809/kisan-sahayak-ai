# Krishi Sahayak RAG - Quick Start Guide

## Complete Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    POST /ingest                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  1. Load document.docx                                       â”‚
â”‚     â†“                                                        â”‚
â”‚  2. Split into chunks (800 chars, 150 overlap)              â”‚
â”‚     â†“                                                        â”‚
â”‚  3. Detect section headings                                 â”‚
â”‚     â†“                                                        â”‚
â”‚  4. Generate embeddings (HuggingFace all-MiniLM-L6-v2)      â”‚
â”‚     â†“                                                        â”‚
â”‚  5. Store in FAISS (vector_store/aif_index/)                â”‚
â”‚                                                              â”‚
â”‚  Response: {"status": "success", "documents_indexed": 42}   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     POST /ask                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  1. Receive question                                         â”‚
â”‚     â†“                                                        â”‚
â”‚  2. Retrieve top 5 similar chunks from FAISS                â”‚
â”‚     â†“                                                        â”‚
â”‚  3. Extract section names from metadata                     â”‚
â”‚     â†“                                                        â”‚
â”‚  4. Format context with sections                            â”‚
â”‚     â†“                                                        â”‚
â”‚  5. Send to LLM (GPT-3.5-turbo) with custom prompt         â”‚
â”‚     â†“                                                        â”‚
â”‚  6. Return answer + source sections                         â”‚
â”‚                                                              â”‚
â”‚  Response: {"answer": "...", "sections": [...]}             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Setup (5 minutes)

### 1. Install Dependencies
```bash
cd kisan-sahayak-ai/krishi_rag
python3.11 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Configure Environment
```bash
cp .env.example .env
# Edit .env and add your OpenAI API key:
# OPENAI_API_KEY=sk-...
```

### 3. Place Your Document
```bash
# Put your document.docx in:
# krishi_rag/data/pdfs/document.docx
```

## Usage

### Start Server
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Ingest Document (First Time)
```bash
curl -X POST http://localhost:8000/ingest
```

**Output:**
```
ðŸ“¥ Starting document ingestion...
1ï¸âƒ£ Loading document from: krishi_rag/data/pdfs/document.docx
âœ“ Loaded and split into 42 chunks
2ï¸âƒ£ Building FAISS vector store...
âœ“ Vector store built and saved
âœ… Ingestion completed successfully!
```

### Ask Questions
```bash
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What are the eligibility criteria for farmers?"}'
```

**Output:**
```json
{
  "answer": "According to the Eligibility Criteria section, farmers must have valid land records and be registered with the local agriculture department. The scheme is available for individual farmers, FPOs, and cooperatives.",
  "sections": ["1. Eligibility Criteria"],
  "success": true
}
```

## Example Questions

```bash
# Eligibility
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "Who is eligible for the AIF scheme?"}'

# Financial Benefits
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What financial benefits are provided?"}'

# Application Process
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "How do I apply for the scheme?"}'

# FAQs
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What documents are required for application?"}'
```

## Interactive API Documentation

Visit these URLs after starting the server:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## Troubleshooting

### Vector store not found
```bash
# Solution: Run ingestion first
curl -X POST http://localhost:8000/ingest
```

### OpenAI API key error
```bash
# Solution: Set OPENAI_API_KEY in .env file
echo "OPENAI_API_KEY=sk-your-key-here" >> .env
```

### Document not found
```bash
# Solution: Ensure document.docx exists
ls data/pdfs/document.docx
```

## Architecture

```
app/
â”œâ”€â”€ main.py           # FastAPI endpoints
â”œâ”€â”€ pdf_loader.py     # Document loading & splitting
â”œâ”€â”€ vector_store.py   # FAISS operations
â”œâ”€â”€ retriever.py      # Document retrieval
â”œâ”€â”€ llm.py            # OpenAI LLM
â”œâ”€â”€ rag_pipeline.py   # RAG orchestration
â””â”€â”€ schemas.py        # Pydantic models

data/
â”œâ”€â”€ pdfs/
â”‚   â””â”€â”€ document.docx # Source document

vector_store/
â””â”€â”€ aif_index/        # FAISS index (auto-generated)
```

## Key Features

âœ… **Section-Aware Retrieval**: Automatically detects and tracks document sections  
âœ… **Metadata Preservation**: Every chunk includes source, file_name, and section  
âœ… **Smart Chunking**: 800 chars with 150 overlap for context preservation  
âœ… **Custom Prompts**: Tailored for AIF scheme with strict context adherence  
âœ… **Structured Responses**: JSON with answer and source sections  
âœ… **Production Ready**: Error handling, logging, CORS, health checks  

## Next Steps

1. âœ… Place your document.docx in data/pdfs/
2. âœ… Set OPENAI_API_KEY in .env
3. âœ… Run: `uvicorn app.main:app --reload`
4. âœ… Ingest: `curl -X POST http://localhost:8000/ingest`
5. âœ… Ask: `curl -X POST http://localhost:8000/ask -H "Content-Type: application/json" -d '{"question": "..."}'`

Happy querying! ðŸš€
